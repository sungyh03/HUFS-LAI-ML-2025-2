# MNIST 분류 실험 결과

## 기본 모델 성능
- 최종 테스트 정확도: 97.30%
- 훈련 시간: 약 1분

## 실험 결과
### 실험 1: 학습률 변경
- 변경사항: Learning rate 1e-3 -> 1e-1
- 최종 테스트 정확도: 23.95%
- 훈련 시간: 약 1분
- 결과: 정확도가 높아지다가 낮아지면서 최종 테스트 정확도가 23.95%로 매우 떨어짐
- 분석: 학습률을 크게 높임으로써 학습이 제대로 진행이 안되고 모델 최적화에 어려움을 겪게 됨

### 실험 2: 모델구조 개선
- 변경사항: 2층 신경망 -> 12층 신경망
- 최종 테스트 정확도: 96.46%
- 훈련 시간: 약 4분
- 결과: 초반 훈련 정확도가 낮고 모델이 학습해 나감에 따라 정확도가 높아지지만 과적합이 살짝 의심됨
- 분석: 모델이 매우 복잡해지면 일어나는 과적합이 일어나야할 것 같지만 의외로 과적합이 일어나지 않았거나 조금 과적합이 일어남.(훈련 정확도(97.09%)와 테스트 정확도(96.46%)의 차이가 크지 않음, 0.63%p 차이) 에포크 수가 적기 때문에 과적합이 일어나지 않았다고 예상됨. (Chat GPT 도움)

### 실험 2.1: 모델구조 개선 + 에포크 증가
- 변경사항: 2층 신경망 -> 12층 신경망 + 에포크 수 10으로 증가
- 최종 테스트 정확도: 97.09%
- 훈련 시간: 약 7분
- 결과: 초반 훈련 정확도가 낮은 것은 동일하고 모델이 학습을 통해 정확도가 높아지는 것은 동일하나 과적합이 더 의심됨 
- 분석: 실험2에서 과적합이 일어나지 않은 이유로 추정되는 에포크 수를 늘렸더니 과적합이 어느 정도 일어났다고 볼 수도 있는 결과가 나타남. (훈련 정확도(98.45%)와 테스트 정확도(97.09%)의 차이가 더욱 늘어남, 1.36%p 차이) (Chat GPT 도움)

### 실험 2.2: 모델구조 개선 + 에포크 더 많이 증가
- 변경사항: 2층 신경망 -> 12층 신경망 + 에포크 수 20으로 증가
- 최종 테스트 정확도: 98.14%
- 훈련 시간: 약 15분
- 결과: 과적합이 실험2.1보다 더욱 크게 일어날 것으로 예상됬지만 과적합이 거의 일어나지 않았고 뛰어난 성능을 보임 
- 분석: 데이터가 충분하고, 학습률, 배치 크기, 옵티마이저 등이 적절히 조합되어 훈련이 안정적으로 진행되어 과적합 억제에 성공했을 가능성이 높을 것으로 예상됨 (훈련 정확도(98.76%)와 테스트 정확도(98.14%)의 차이가 더욱 늘어남, 0.62%p 차이) (Chat GPT 도움)


## 결론 및 인사이트
- 가장 효과적인 개선 방법: 모델의 복잡도 증가 및 에포크 수 증가, 적절한 학습률 설정 
- 관찰된 패턴: 복잡한 모델일수록 에포크 수가 증가할수록 훈련 시간이 늘어나며 적절한 모델구조와 에포크 학습률을 설정할 경우 모델의 정확도가 증가함
- 추가 개선 아이디어: 학습률과 모델구조 개선, 에포크 수 증감 등등을 적절히 조절